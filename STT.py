import os
import io
import pyaudio
import numpy as np
from pydub import AudioSegment
from google.cloud import speech
from google.oauth2 import service_account

# ===== ì„¤ì • =====
json_file = r"C:\Temp\SleepVoice\STTS.json"  # ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ê²½ë¡œ
RATE = 16000
CHANNELS = 1
FORMAT = pyaudio.paInt16
CHUNK = int(RATE / 10)  # 0.1ì´ˆ ë‹¨ìœ„
SILENCE_LIMIT = 2  # ë¬´ìŒ ì§€ì† ì‹œê°„ (ì´ˆ)
THRESHOLD = 500  # ì†Œë¦¬ ê°ì§€ ì„ê³„ê°’ (ê°’ì´ ë‚®ì„ìˆ˜ë¡ ì‘ì€ ì†Œë¦¬ë„ ì¸ì‹)

# ===== ì¸ì¦ =====
credentials = service_account.Credentials.from_service_account_file(json_file)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = json_file
client = speech.SpeechClient(credentials=credentials)

def record_until_silence():
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)

    print("ğŸ™ ë§í•˜ì„¸ìš”... (ë¬´ìŒì´ ê°ì§€ë˜ë©´ ìë™ ì¢…ë£Œ)")
    frames = []
    silence_counter = 0

    while True:
        data = stream.read(CHUNK)
        frames.append(data)

        # numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ì†Œë¦¬ í¬ê¸° ì¸¡ì •
        audio_data = np.frombuffer(data, dtype=np.int16)
        volume = np.abs(audio_data).mean()

        if volume < THRESHOLD:
            silence_counter += 0.1
        else:
            silence_counter = 0  # ì†Œë¦¬ê°€ ë“¤ë¦¬ë©´ ì¹´ìš´í„° ì´ˆê¸°í™”

        if silence_counter > SILENCE_LIMIT:
            print("â¹ ë¬´ìŒ ê°ì§€, ë…¹ìŒ ì¢…ë£Œ")
            break

    stream.stop_stream()
    stream.close()
    p.terminate()

    return b"".join(frames)

def audio_to_wav(audio_bytes):
    audio_segment = AudioSegment(
        data=audio_bytes,
        sample_width=2,
        frame_rate=RATE,
        channels=CHANNELS
    )
    buffer = io.BytesIO()
    audio_segment.export(buffer, format="wav")
    buffer.seek(0)
    return buffer

def transcribe_audio(audio_buffer):
    audio = speech.RecognitionAudio(content=audio_buffer.read())
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=RATE,
        language_code="ko-KR"
    )
    response = client.recognize(config=config, audio=audio)
    for result in response.results:
        print("ğŸ—£ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", result.alternatives[0].transcript)

if __name__ == "__main__":
    audio_bytes = record_until_silence()
    wav_buffer = audio_to_wav(audio_bytes)
    transcribe_audio(wav_buffer)
